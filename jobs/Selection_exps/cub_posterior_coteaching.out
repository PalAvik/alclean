============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius+and+Lisa#SoftwarepolicySnelliusandLisa-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Found existing installation: AL-cleaning 1.0
Uninstalling AL-cleaning-1.0:
  Successfully uninstalled AL-cleaning-1.0
Obtaining file:///gpfs/home6/scur1936/al-label-cleaning
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Installing collected packages: AL-cleaning
  Running setup.py develop for AL-cleaning
Successfully installed AL-cleaning-1.0
[nltk_data] Downloading package wordnet to /home/scur1936/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
root: INFO   Preparing dataset: CUB (N=8251)
root: INFO   Class distribution (%) (true labels): [0.43631075 0.64234638 0.50902921 0.44843049 0.36359229 0.41207126
 0.44843049 0.41207126 0.54538844 0.47266998 0.48478972 0.48478972
 0.50902921 0.53326869 0.42419101 0.53326869 0.50902921 0.37571203
 0.50902921 0.50902921 0.49690947 0.43631075 0.48478972 0.50902921
 0.52114895 0.52114895 0.42419101 0.49690947 0.54538844 0.48478972
 0.44843049 0.48478972 0.52114895 0.47266998 0.49690947 0.54538844
 0.54538844 0.43631075 0.52114895 0.53326869 0.44843049 0.43631075
 0.6181069  0.50902921 0.48478972 0.50902921 0.54538844 0.43631075
 0.48478972 0.54538844 0.47266998 0.39995152 0.6181069  0.50902921
 0.46055024 0.59386741 0.33935281 0.43631075 0.49690947 0.43631075
 0.52114895 0.60598715 0.56962792 0.46055024 0.58174767 0.35147255
 0.49690947 0.50902921 0.52114895 0.48478972 0.47266998 0.50902921
 0.39995152 0.55750818 0.55750818 0.49690947 0.55750818 0.42419101
 0.56962792 0.50902921 0.43631075 0.44843049 0.58174767 0.43631075
 0.47266998 0.58174767 0.52114895 0.53326869 0.48478972 0.49690947
 0.59386741 0.46055024 0.53326869 0.50902921 0.41207126 0.59386741
 0.48478972 0.6181069  0.49690947 0.41207126 0.42419101 0.48478972
 0.52114895 0.44843049 0.44843049 0.58174767 0.54538844 0.6181069
 0.44843049 0.52114895 0.49690947 0.49690947 0.52114895 0.53326869
 0.49690947 0.52114895 0.44843049 0.31511332 0.48478972 0.49690947
 0.46055024 0.48478972 0.46055024 0.55750818 0.60598715 0.42419101
 0.47266998 0.38783178 0.55750818 0.55750818 0.47266998 0.58174767
 0.64234638 0.54538844 0.59386741 0.64234638 0.47266998 0.41207126
 0.59386741 0.46055024 0.38783178 0.52114895 0.65446613 0.56962792
 0.52114895 0.49690947 0.47266998 0.50902921 0.54538844 0.55750818
 0.55750818 0.42419101 0.53326869 0.50902921 0.59386741 0.43631075
 0.53326869 0.47266998 0.46055024 0.44843049 0.52114895 0.44843049
 0.69082535 0.60598715 0.43631075 0.42419101 0.6181069  0.47266998
 0.49690947 0.55750818 0.48478972 0.47266998 0.49690947 0.47266998
 0.54538844 0.39995152 0.56962792 0.47266998 0.44843049 0.50902921
 0.46055024 0.36359229 0.60598715 0.46055024 0.53326869 0.48478972
 0.58174767 0.56962792 0.50902921 0.41207126 0.53326869 0.39995152
 0.56962792 0.46055024 0.60598715 0.47266998 0.36359229 0.63022664
 0.39995152 0.46055024]
root: INFO   Ambiguous mislabeled cases: 0.012119743061447098%
root: INFO   Clear mislabeled cases: 39.89819415828384%

root: INFO   Preparing dataset: CUB (N=3537)
root: INFO   Class distribution (%) (true labels): [0.48063331 0.36754312 0.48063331 0.65026859 0.33927057 0.48063331
 0.25445293 0.36754312 0.67854114 0.45236076 0.31099802 0.56545095
 0.50890585 0.45236076 0.50890585 0.5371784  0.42408821 0.42408821
 0.45236076 0.48063331 0.59372349 0.56545095 0.31099802 0.5371784
 0.45236076 0.48063331 0.70681368 0.50890585 0.50890585 0.48063331
 0.39581566 0.50890585 0.56545095 0.5371784  0.56545095 0.42408821
 0.45236076 0.50890585 0.70681368 0.45236076 0.42408821 0.45236076
 0.5371784  0.50890585 0.56545095 0.50890585 0.56545095 0.5371784
 0.56545095 0.59372349 0.48063331 0.42408821 0.5371784  0.59372349
 0.5371784  0.70681368 0.50890585 0.62199604 0.5371784  0.36754312
 0.5371784  0.48063331 0.48063331 0.59372349 0.39581566 0.48063331
 0.67854114 0.31099802 0.5371784  0.56545095 0.59372349 0.50890585
 0.65026859 0.39581566 0.42408821 0.5371784  0.56545095 0.50890585
 0.5371784  0.48063331 0.5371784  0.56545095 0.42408821 0.48063331
 0.59372349 0.33927057 0.48063331 0.45236076 0.59372349 0.50890585
 0.31099802 0.62199604 0.45236076 0.50890585 0.39581566 0.31099802
 0.42408821 0.70681368 0.5371784  0.56545095 0.59372349 0.56545095
 0.48063331 0.65026859 0.33927057 0.33927057 0.28272547 0.36754312
 0.65026859 0.48063331 0.50890585 0.56545095 0.39581566 0.28272547
 0.76335878 0.5371784  0.33927057 0.42408821 0.50890585 0.39581566
 0.5371784  0.50890585 0.50890585 0.56545095 0.56545095 0.48063331
 0.45236076 0.56545095 0.5371784  0.5371784  0.5371784  0.73508623
 0.5371784  0.42408821 0.36754312 0.56545095 0.56545095 0.31099802
 0.42408821 0.50890585 0.50890585 0.42408821 0.45236076 0.45236076
 0.62199604 0.39581566 0.50890585 0.45236076 0.39581566 0.39581566
 0.39581566 0.42408821 0.59372349 0.31099802 0.48063331 0.48063331
 0.50890585 0.59372349 0.59372349 0.70681368 0.56545095 0.42408821
 0.48063331 0.50890585 0.42408821 0.50890585 0.65026859 0.59372349
 0.62199604 0.48063331 0.5371784  0.48063331 0.56545095 0.50890585
 0.45236076 0.62199604 0.70681368 0.42408821 0.45236076 0.36754312
 0.56545095 0.48063331 0.48063331 0.42408821 0.50890585 0.50890585
 0.5371784  0.33927057 0.42408821 0.42408821 0.56545095 0.5371784
 0.56545095 0.62199604 0.73508623 0.45236076 0.45236076 0.39581566
 0.45236076 0.62199604]
root: INFO   Ambiguous mislabeled cases: 0.05654509471303364%
root: INFO   Clear mislabeled cases: 39.468476109697484%

root: INFO   Training dataset size N=8251
root: INFO   Validation dataset size N=3537
root: INFO   
root: INFO   Loading curated labels from HDF5 file: /gpfs/home6/scur1936/al-label-cleaning/logs/main_simulation_benchmark/SelectorResults/cub_noise_20/co_teaching/PosteriorBasedSelector/val/seed_12/simulator_output.hdf
root: INFO   Number of relabels: 1398
root: INFO   Selector used in relabelling: Coteaching
root: INFO   Label accuracy: 72.85835453774385
root: INFO   
root: INFO   Loading curated labels from HDF5 file: /gpfs/home6/scur1936/al-label-cleaning/logs/main_simulation_benchmark/SelectorResults/cub_noise_20/co_teaching/PosteriorBasedSelector/val/seed_1/simulator_output.hdf
root: INFO   Number of relabels: 1398
root: INFO   Selector used in relabelling: Coteaching
root: INFO   Label accuracy: 72.51908396946565
root: INFO   
root: INFO   Loading curated labels from HDF5 file: /gpfs/home6/scur1936/al-label-cleaning/logs/main_simulation_benchmark/SelectorResults/cub_noise_20/co_teaching/PosteriorBasedSelector/val/seed_123/simulator_output.hdf
root: INFO   Number of relabels: 1398
root: INFO   Selector used in relabelling: Coteaching
root: INFO   Label accuracy: 72.74526434831779
root: INFO   Preparing dataset: CUB (N=8251)
root: INFO   Class distribution (%) (true labels): [0.43631075 0.64234638 0.50902921 0.44843049 0.36359229 0.41207126
 0.44843049 0.41207126 0.54538844 0.47266998 0.48478972 0.48478972
 0.50902921 0.53326869 0.42419101 0.53326869 0.50902921 0.37571203
 0.50902921 0.50902921 0.49690947 0.43631075 0.48478972 0.50902921
 0.52114895 0.52114895 0.42419101 0.49690947 0.54538844 0.48478972
 0.44843049 0.48478972 0.52114895 0.47266998 0.49690947 0.54538844
 0.54538844 0.43631075 0.52114895 0.53326869 0.44843049 0.43631075
 0.6181069  0.50902921 0.48478972 0.50902921 0.54538844 0.43631075
 0.48478972 0.54538844 0.47266998 0.39995152 0.6181069  0.50902921
 0.46055024 0.59386741 0.33935281 0.43631075 0.49690947 0.43631075
 0.52114895 0.60598715 0.56962792 0.46055024 0.58174767 0.35147255
 0.49690947 0.50902921 0.52114895 0.48478972 0.47266998 0.50902921
 0.39995152 0.55750818 0.55750818 0.49690947 0.55750818 0.42419101
 0.56962792 0.50902921 0.43631075 0.44843049 0.58174767 0.43631075
 0.47266998 0.58174767 0.52114895 0.53326869 0.48478972 0.49690947
 0.59386741 0.46055024 0.53326869 0.50902921 0.41207126 0.59386741
 0.48478972 0.6181069  0.49690947 0.41207126 0.42419101 0.48478972
 0.52114895 0.44843049 0.44843049 0.58174767 0.54538844 0.6181069
 0.44843049 0.52114895 0.49690947 0.49690947 0.52114895 0.53326869
 0.49690947 0.52114895 0.44843049 0.31511332 0.48478972 0.49690947
 0.46055024 0.48478972 0.46055024 0.55750818 0.60598715 0.42419101
 0.47266998 0.38783178 0.55750818 0.55750818 0.47266998 0.58174767
 0.64234638 0.54538844 0.59386741 0.64234638 0.47266998 0.41207126
 0.59386741 0.46055024 0.38783178 0.52114895 0.65446613 0.56962792
 0.52114895 0.49690947 0.47266998 0.50902921 0.54538844 0.55750818
 0.55750818 0.42419101 0.53326869 0.50902921 0.59386741 0.43631075
 0.53326869 0.47266998 0.46055024 0.44843049 0.52114895 0.44843049
 0.69082535 0.60598715 0.43631075 0.42419101 0.6181069  0.47266998
 0.49690947 0.55750818 0.48478972 0.47266998 0.49690947 0.47266998
 0.54538844 0.39995152 0.56962792 0.47266998 0.44843049 0.50902921
 0.46055024 0.36359229 0.60598715 0.46055024 0.53326869 0.48478972
 0.58174767 0.56962792 0.50902921 0.41207126 0.53326869 0.39995152
 0.56962792 0.46055024 0.60598715 0.47266998 0.36359229 0.63022664
 0.39995152 0.46055024]
root: INFO   Ambiguous mislabeled cases: 0.012119743061447098%
root: INFO   Clear mislabeled cases: 39.89819415828384%

root: INFO   Preparing dataset: CUB (N=3537)
root: INFO   Class distribution (%) (true labels): [0.48063331 0.36754312 0.48063331 0.65026859 0.33927057 0.48063331
 0.25445293 0.36754312 0.67854114 0.45236076 0.31099802 0.56545095
 0.50890585 0.45236076 0.50890585 0.5371784  0.42408821 0.42408821
 0.45236076 0.48063331 0.59372349 0.56545095 0.31099802 0.5371784
 0.45236076 0.48063331 0.70681368 0.50890585 0.50890585 0.48063331
 0.39581566 0.50890585 0.56545095 0.5371784  0.56545095 0.42408821
 0.45236076 0.50890585 0.70681368 0.45236076 0.42408821 0.45236076
 0.5371784  0.50890585 0.56545095 0.50890585 0.56545095 0.5371784
 0.56545095 0.59372349 0.48063331 0.42408821 0.5371784  0.59372349
 0.5371784  0.70681368 0.50890585 0.62199604 0.5371784  0.36754312
 0.5371784  0.48063331 0.48063331 0.59372349 0.39581566 0.48063331
 0.67854114 0.31099802 0.5371784  0.56545095 0.59372349 0.50890585
 0.65026859 0.39581566 0.42408821 0.5371784  0.56545095 0.50890585
 0.5371784  0.48063331 0.5371784  0.56545095 0.42408821 0.48063331
 0.59372349 0.33927057 0.48063331 0.45236076 0.59372349 0.50890585
 0.31099802 0.62199604 0.45236076 0.50890585 0.39581566 0.31099802
 0.42408821 0.70681368 0.5371784  0.56545095 0.59372349 0.56545095
 0.48063331 0.65026859 0.33927057 0.33927057 0.28272547 0.36754312
 0.65026859 0.48063331 0.50890585 0.56545095 0.39581566 0.28272547
 0.76335878 0.5371784  0.33927057 0.42408821 0.50890585 0.39581566
 0.5371784  0.50890585 0.50890585 0.56545095 0.56545095 0.48063331
 0.45236076 0.56545095 0.5371784  0.5371784  0.5371784  0.73508623
 0.5371784  0.42408821 0.36754312 0.56545095 0.56545095 0.31099802
 0.42408821 0.50890585 0.50890585 0.42408821 0.45236076 0.45236076
 0.62199604 0.39581566 0.50890585 0.45236076 0.39581566 0.39581566
 0.39581566 0.42408821 0.59372349 0.31099802 0.48063331 0.48063331
 0.50890585 0.59372349 0.59372349 0.70681368 0.56545095 0.42408821
 0.48063331 0.50890585 0.42408821 0.50890585 0.65026859 0.59372349
 0.62199604 0.48063331 0.5371784  0.48063331 0.56545095 0.50890585
 0.45236076 0.62199604 0.70681368 0.42408821 0.45236076 0.36754312
 0.56545095 0.48063331 0.48063331 0.42408821 0.50890585 0.50890585
 0.5371784  0.33927057 0.42408821 0.42408821 0.56545095 0.5371784
 0.56545095 0.62199604 0.73508623 0.45236076 0.45236076 0.39581566
 0.45236076 0.62199604]
root: INFO   Ambiguous mislabeled cases: 0.05654509471303364%
root: INFO   Clear mislabeled cases: 39.468476109697484%

root: INFO   Training dataset size N=8251
root: INFO   Validation dataset size N=3537
/home/scur1936/.conda/envs/alclean/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/scur1936/.conda/envs/alclean/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
root: INFO   Preparing dataset: CUB (N=8251)
root: INFO   Class distribution (%) (true labels): [0.43631075 0.64234638 0.50902921 0.44843049 0.36359229 0.41207126
 0.44843049 0.41207126 0.54538844 0.47266998 0.48478972 0.48478972
 0.50902921 0.53326869 0.42419101 0.53326869 0.50902921 0.37571203
 0.50902921 0.50902921 0.49690947 0.43631075 0.48478972 0.50902921
 0.52114895 0.52114895 0.42419101 0.49690947 0.54538844 0.48478972
 0.44843049 0.48478972 0.52114895 0.47266998 0.49690947 0.54538844
 0.54538844 0.43631075 0.52114895 0.53326869 0.44843049 0.43631075
 0.6181069  0.50902921 0.48478972 0.50902921 0.54538844 0.43631075
 0.48478972 0.54538844 0.47266998 0.39995152 0.6181069  0.50902921
 0.46055024 0.59386741 0.33935281 0.43631075 0.49690947 0.43631075
 0.52114895 0.60598715 0.56962792 0.46055024 0.58174767 0.35147255
 0.49690947 0.50902921 0.52114895 0.48478972 0.47266998 0.50902921
 0.39995152 0.55750818 0.55750818 0.49690947 0.55750818 0.42419101
 0.56962792 0.50902921 0.43631075 0.44843049 0.58174767 0.43631075
 0.47266998 0.58174767 0.52114895 0.53326869 0.48478972 0.49690947
 0.59386741 0.46055024 0.53326869 0.50902921 0.41207126 0.59386741
 0.48478972 0.6181069  0.49690947 0.41207126 0.42419101 0.48478972
 0.52114895 0.44843049 0.44843049 0.58174767 0.54538844 0.6181069
 0.44843049 0.52114895 0.49690947 0.49690947 0.52114895 0.53326869
 0.49690947 0.52114895 0.44843049 0.31511332 0.48478972 0.49690947
 0.46055024 0.48478972 0.46055024 0.55750818 0.60598715 0.42419101
 0.47266998 0.38783178 0.55750818 0.55750818 0.47266998 0.58174767
 0.64234638 0.54538844 0.59386741 0.64234638 0.47266998 0.41207126
 0.59386741 0.46055024 0.38783178 0.52114895 0.65446613 0.56962792
 0.52114895 0.49690947 0.47266998 0.50902921 0.54538844 0.55750818
 0.55750818 0.42419101 0.53326869 0.50902921 0.59386741 0.43631075
 0.53326869 0.47266998 0.46055024 0.44843049 0.52114895 0.44843049
 0.69082535 0.60598715 0.43631075 0.42419101 0.6181069  0.47266998
 0.49690947 0.55750818 0.48478972 0.47266998 0.49690947 0.47266998
 0.54538844 0.39995152 0.56962792 0.47266998 0.44843049 0.50902921
 0.46055024 0.36359229 0.60598715 0.46055024 0.53326869 0.48478972
 0.58174767 0.56962792 0.50902921 0.41207126 0.53326869 0.39995152
 0.56962792 0.46055024 0.60598715 0.47266998 0.36359229 0.63022664
 0.39995152 0.46055024]
root: INFO   Ambiguous mislabeled cases: 0.012119743061447098%
root: INFO   Clear mislabeled cases: 39.89819415828384%

root: INFO   Preparing dataset: CUB (N=3537)
root: INFO   Class distribution (%) (true labels): [0.48063331 0.36754312 0.48063331 0.65026859 0.33927057 0.48063331
 0.25445293 0.36754312 0.67854114 0.45236076 0.31099802 0.56545095
 0.50890585 0.45236076 0.50890585 0.5371784  0.42408821 0.42408821
 0.45236076 0.48063331 0.59372349 0.56545095 0.31099802 0.5371784
 0.45236076 0.48063331 0.70681368 0.50890585 0.50890585 0.48063331
 0.39581566 0.50890585 0.56545095 0.5371784  0.56545095 0.42408821
 0.45236076 0.50890585 0.70681368 0.45236076 0.42408821 0.45236076
 0.5371784  0.50890585 0.56545095 0.50890585 0.56545095 0.5371784
 0.56545095 0.59372349 0.48063331 0.42408821 0.5371784  0.59372349
 0.5371784  0.70681368 0.50890585 0.62199604 0.5371784  0.36754312
 0.5371784  0.48063331 0.48063331 0.59372349 0.39581566 0.48063331
 0.67854114 0.31099802 0.5371784  0.56545095 0.59372349 0.50890585
 0.65026859 0.39581566 0.42408821 0.5371784  0.56545095 0.50890585
 0.5371784  0.48063331 0.5371784  0.56545095 0.42408821 0.48063331
 0.59372349 0.33927057 0.48063331 0.45236076 0.59372349 0.50890585
 0.31099802 0.62199604 0.45236076 0.50890585 0.39581566 0.31099802
 0.42408821 0.70681368 0.5371784  0.56545095 0.59372349 0.56545095
 0.48063331 0.65026859 0.33927057 0.33927057 0.28272547 0.36754312
 0.65026859 0.48063331 0.50890585 0.56545095 0.39581566 0.28272547
 0.76335878 0.5371784  0.33927057 0.42408821 0.50890585 0.39581566
 0.5371784  0.50890585 0.50890585 0.56545095 0.56545095 0.48063331
 0.45236076 0.56545095 0.5371784  0.5371784  0.5371784  0.73508623
 0.5371784  0.42408821 0.36754312 0.56545095 0.56545095 0.31099802
 0.42408821 0.50890585 0.50890585 0.42408821 0.45236076 0.45236076
 0.62199604 0.39581566 0.50890585 0.45236076 0.39581566 0.39581566
 0.39581566 0.42408821 0.59372349 0.31099802 0.48063331 0.48063331
 0.50890585 0.59372349 0.59372349 0.70681368 0.56545095 0.42408821
 0.48063331 0.50890585 0.42408821 0.50890585 0.65026859 0.59372349
 0.62199604 0.48063331 0.5371784  0.48063331 0.56545095 0.50890585
 0.45236076 0.62199604 0.70681368 0.42408821 0.45236076 0.36754312
 0.56545095 0.48063331 0.48063331 0.42408821 0.50890585 0.50890585
 0.5371784  0.33927057 0.42408821 0.42408821 0.56545095 0.5371784
 0.56545095 0.62199604 0.73508623 0.45236076 0.45236076 0.39581566
 0.45236076 0.62199604]
root: INFO   Ambiguous mislabeled cases: 0.05654509471303364%
root: INFO   Clear mislabeled cases: 39.468476109697484%

root: INFO   Training dataset size N=8251
root: INFO   Validation dataset size N=3537
root: INFO   No samples will be excluded in co-teaching for the first 25 epochs.
root: WARNING Num gradual 10 <= num warm up epochs. This argument will be ignored.
root: INFO   Loading model-0 from checkpoint:
 /gpfs/home6/scur1936/al-label-cleaning/logs/cub_noise_20_scratch/co_teaching/seed_1/checkpoints/checkpoint_model_0_last_epoch.pt
root: INFO   Loading model-1 from checkpoint:
 /gpfs/home6/scur1936/al-label-cleaning/logs/cub_noise_20_scratch/co_teaching/seed_1/checkpoints/checkpoint_model_1_last_epoch.pt
root: INFO   
                model  run_id      dataset  count   accuracy  top_n_accuracy  cross_entropy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       accuracy_per_class
0  resnet_co_teaching       0        clean   3537  34.294600       48.770144       0.607533  [11.765, 16.667, 16.667, 43.478, 21.429, 36.364, 41.667, 21.429, 4.762, 25.0, 0.0, 36.842, 66.667, 50.0, 50.0, 52.632, 73.333, 18.75, 40.0, 58.824, 43.478, 25.0, 17.647, 37.5, 53.846, 42.105, 17.391, 94.444, 15.789, 18.75, 25.0, 21.429, 16.667, 44.444, 38.095, 66.667, 18.75, 19.048, 20.0, 17.647, 0.0, 66.667, 25.0, 55.556, 55.0, 55.556, 39.13, 43.75, 55.0, 38.889, 31.25, 22.222, 60.0, 21.053, 31.579, 38.095, 37.5, 45.455, 0.0, 9.091, 57.895, 5.263, 60.0, 4.762, 33.333, 7.143, 5.556, 42.105, 17.647, 85.0, 16.667, 57.143, 20.833, 41.176, 63.636, 36.842, 73.684, 47.368, 50.0, 47.368, 37.5, 13.333, 93.75, 58.824, 85.714, 66.667, 52.941, 87.5, 35.0, 63.158, 36.364, 45.455, 81.25, 72.222, 14.286, 26.667, 23.81, 53.333, 42.105, 26.087, ...]
2  resnet_co_teaching       0  co-teaching   3537  29.657902       43.709358       0.661232    [17.647, 0.0, 16.667, 43.478, 14.286, 54.545, 50.0, 14.286, 4.762, 18.75, 0.0, 26.316, 66.667, 38.889, 31.25, 36.842, 73.333, 12.5, 40.0, 58.824, 39.13, 25.0, 23.529, 31.25, 38.462, 31.579, 17.391, 94.444, 10.526, 12.5, 10.0, 14.286, 5.556, 38.889, 47.619, 66.667, 12.5, 23.81, 13.333, 11.765, 0.0, 66.667, 31.25, 55.556, 55.0, 55.556, 39.13, 31.25, 55.0, 33.333, 43.75, 16.667, 30.0, 21.053, 31.579, 28.571, 37.5, 45.455, 0.0, 22.727, 31.579, 10.526, 40.0, 4.762, 25.0, 14.286, 5.556, 15.789, 11.765, 85.0, 27.778, 28.571, 29.167, 35.294, 45.455, 36.842, 73.684, 31.579, 31.25, 36.842, 33.333, 6.667, 56.25, 58.824, 85.714, 66.667, 52.941, 87.5, 45.0, 42.105, 36.364, 45.455, 81.25, 72.222, 14.286, 13.333, 9.524, 40.0, 42.105, 21.739, ...]
1  resnet_co_teaching       0        noisy   3537  26.095561       38.733390       0.802033   [17.647, 0.0, 16.667, 43.478, 14.286, 54.545, 50.0, 14.286, 4.762, 18.75, 0.0, 21.053, 66.667, 33.333, 31.25, 36.842, 73.333, 12.5, 40.0, 58.824, 39.13, 25.0, 17.647, 31.25, 30.769, 31.579, 17.391, 94.444, 10.526, 6.25, 10.0, 14.286, 5.556, 38.889, 47.619, 66.667, 12.5, 23.81, 13.333, 5.882, 0.0, 33.333, 25.0, 55.556, 55.0, 55.556, 39.13, 31.25, 55.0, 33.333, 43.75, 16.667, 30.0, 21.053, 31.579, 19.048, 33.333, 45.455, 0.0, 18.182, 15.789, 10.526, 26.667, 4.762, 25.0, 14.286, 5.556, 15.789, 11.765, 85.0, 27.778, 28.571, 29.167, 29.412, 36.364, 36.842, 73.684, 31.579, 25.0, 26.316, 25.0, 6.667, 43.75, 58.824, 85.714, 66.667, 52.941, 87.5, 45.0, 42.105, 36.364, 45.455, 81.25, 72.222, 14.286, 13.333, 9.524, 33.333, 42.105, 21.739, ...]
root: INFO   
                model      dataset   accuracy       count     cross_entropy    
                                         mean std    mean std          mean std
0  resnet_co_teaching        clean  34.294600 NaN  3537.0 NaN      0.607533 NaN
1  resnet_co_teaching  co-teaching  29.657902 NaN  3537.0 NaN      0.661232 NaN
2  resnet_co_teaching        noisy  26.095561 NaN  3537.0 NaN      0.802033 NaN

JOB STATISTICS
==============
Job ID: 4791207
Cluster: snellius
User/Group: scur1936/scur1936
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:06:45
CPU Efficiency: 17.72% of 00:38:06 core-walltime
Job Wall-clock time: 00:02:07
Memory Utilized: 3.08 GB
Memory Efficiency: 2.57% of 120.00 GB
